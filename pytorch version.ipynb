{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "#now to import everyhting from classes.py and functions.py\n",
    "from classes import *\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "NVIDIA GeForce RTX 4070 SUPER\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available()) \n",
    "print(torch.cuda.current_device())  \n",
    "print(torch.cuda.get_device_name(0))  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define Paths and Split Data\n",
    "base_dir = '/Users/hunte/Desktop/PetImages'\n",
    "\n",
    "dog_files,cat_files = gather_paths(base_dir)\n",
    "\n",
    "train_files, train_labels, val_files, val_labels = create_train_val_split(dog_files, cat_files, val_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation and Preprocessing\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), shear=0.2, scale=(0.7, 1.3)),\n",
    "    transforms.ColorJitter(brightness=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Create Datasets and DataLoaders (see classes.py for PetDataset class)\n",
    "train_dataset = PetDataset(train_files, train_labels, transform=train_transforms)\n",
    "val_dataset = PetDataset(val_files, val_labels, transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PetCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=16384, out_features=512, bias=True)\n",
      "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define CNN Model (see classes.py)\n",
    "model = PetCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering training loop...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 [Train]: 100%|██████████| 625/625 [00:50<00:00, 12.35it/s, loss=0.642, batch_acc=0.633]\n",
      "Epoch 1/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.48it/s, loss=0.397, batch_acc=0.75] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Acc: 0.6507, Val Acc: 0.7424, Train Loss: 0.6303, Val Loss: 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.06it/s, loss=0.635, batch_acc=0.767]\n",
      "Epoch 2/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.54it/s, loss=0.813, batch_acc=0.5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Acc: 0.7374, Val Acc: 0.7430, Train Loss: 0.5261, Val Loss: 0.5103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 [Train]: 100%|██████████| 625/625 [00:52<00:00, 12.01it/s, loss=0.446, batch_acc=0.767]\n",
      "Epoch 3/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.80it/s, loss=0.122, batch_acc=1]     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Acc: 0.7831, Val Acc: 0.7986, Train Loss: 0.4614, Val Loss: 0.4379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 [Train]: 100%|██████████| 625/625 [00:52<00:00, 12.02it/s, loss=0.252, batch_acc=0.933]\n",
      "Epoch 4/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.74it/s, loss=0.733, batch_acc=0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Acc: 0.8128, Val Acc: 0.7656, Train Loss: 0.4175, Val Loss: 0.4886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.24it/s, loss=0.413, batch_acc=0.833]\n",
      "Epoch 5/20 [Val]: 100%|██████████| 157/157 [00:08<00:00, 18.17it/s, loss=0.824, batch_acc=0.75] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Acc: 0.8269, Val Acc: 0.7964, Train Loss: 0.3887, Val Loss: 0.4572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 [Train]: 100%|██████████| 625/625 [00:52<00:00, 12.01it/s, loss=0.397, batch_acc=0.767]\n",
      "Epoch 6/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.56it/s, loss=0.635, batch_acc=0.75] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Acc: 0.8368, Val Acc: 0.8230, Train Loss: 0.3648, Val Loss: 0.4023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.07it/s, loss=0.278, batch_acc=0.867]\n",
      "Epoch 7/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.73it/s, loss=0.535, batch_acc=0.75] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Acc: 0.8465, Val Acc: 0.8384, Train Loss: 0.3484, Val Loss: 0.3556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.13it/s, loss=0.248, batch_acc=0.933]\n",
      "Epoch 8/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.66it/s, loss=0.327, batch_acc=0.75] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Acc: 0.8564, Val Acc: 0.8922, Train Loss: 0.3311, Val Loss: 0.2599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.12it/s, loss=0.268, batch_acc=0.833]\n",
      "Epoch 9/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.69it/s, loss=0.235, batch_acc=0.875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Train Acc: 0.8623, Val Acc: 0.9044, Train Loss: 0.3159, Val Loss: 0.2316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.09it/s, loss=0.37, batch_acc=0.767] \n",
      "Epoch 10/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.71it/s, loss=0.0898, batch_acc=1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Train Acc: 0.8694, Val Acc: 0.9084, Train Loss: 0.3035, Val Loss: 0.2221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.11it/s, loss=0.215, batch_acc=0.933] \n",
      "Epoch 11/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.74it/s, loss=0.271, batch_acc=0.875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Train Acc: 0.8717, Val Acc: 0.8668, Train Loss: 0.2941, Val Loss: 0.3091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.08it/s, loss=0.299, batch_acc=0.833] \n",
      "Epoch 12/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.59it/s, loss=0.0165, batch_acc=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Train Acc: 0.8788, Val Acc: 0.8562, Train Loss: 0.2818, Val Loss: 0.3362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.09it/s, loss=0.402, batch_acc=0.833] \n",
      "Epoch 13/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.63it/s, loss=0.159, batch_acc=0.875] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Train Acc: 0.8804, Val Acc: 0.9160, Train Loss: 0.2779, Val Loss: 0.2059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.08it/s, loss=0.167, batch_acc=0.967] \n",
      "Epoch 14/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.60it/s, loss=0.0964, batch_acc=1]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Train Acc: 0.8884, Val Acc: 0.9050, Train Loss: 0.2659, Val Loss: 0.2408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.03it/s, loss=0.409, batch_acc=0.8]   \n",
      "Epoch 15/20 [Val]: 100%|██████████| 157/157 [09:31<00:00,  3.64s/it, loss=0.0577, batch_acc=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Train Acc: 0.8938, Val Acc: 0.9042, Train Loss: 0.2566, Val Loss: 0.2398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.08it/s, loss=0.443, batch_acc=0.767] \n",
      "Epoch 16/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 17.15it/s, loss=0.0748, batch_acc=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Train Acc: 0.8940, Val Acc: 0.9258, Train Loss: 0.2516, Val Loss: 0.1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 [Train]: 100%|██████████| 625/625 [00:51<00:00, 12.23it/s, loss=0.381, batch_acc=0.833] \n",
      "Epoch 17/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.26it/s, loss=0.171, batch_acc=0.875]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Train Acc: 0.8996, Val Acc: 0.8976, Train Loss: 0.2443, Val Loss: 0.2598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 [Train]: 100%|██████████| 625/625 [00:53<00:00, 11.78it/s, loss=0.537, batch_acc=0.733] \n",
      "Epoch 18/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.27it/s, loss=0.0659, batch_acc=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Train Acc: 0.9006, Val Acc: 0.9338, Train Loss: 0.2386, Val Loss: 0.1636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 [Train]: 100%|██████████| 625/625 [00:52<00:00, 11.82it/s, loss=0.116, batch_acc=0.967] \n",
      "Epoch 19/20 [Val]: 100%|██████████| 157/157 [00:09<00:00, 16.06it/s, loss=0.0243, batch_acc=1]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Train Acc: 0.9057, Val Acc: 0.9308, Train Loss: 0.2279, Val Loss: 0.1692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 [Train]: 100%|██████████| 625/625 [00:56<00:00, 11.05it/s, loss=0.163, batch_acc=0.933] \n",
      "Epoch 20/20 [Val]: 100%|██████████| 157/157 [00:10<00:00, 15.60it/s, loss=0.0198, batch_acc=1]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Train Acc: 0.9061, Val Acc: 0.9344, Train Loss: 0.2276, Val Loss: 0.1724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = train_model(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m      3\u001b[39m plt.subplot(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m plt.plot(\u001b[43mhistory\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mtrain_acc\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mTrain Accuracy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m plt.plot(history[\u001b[33m'\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m'\u001b[39m], label=\u001b[33m'\u001b[39m\u001b[33mVal Accuracy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mAccuracy\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6: Visualize Results\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "plt.plot(history['val_acc'], label='Val Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Bonus: Visualize Augmented Images\n",
    "model.eval()\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images[:4].to(device), labels[:4].to(device)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(4):\n",
    "    img = images[i].cpu().numpy().transpose((1, 2, 0))  # Convert to HWC format\n",
    "    img = img * 0.5 + 0.5  # Denormalize\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.title('Cat' if labels[i].item() == 0 else 'Dog')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot register a hook on a tensor that doesn't require gradient",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m val_loader:\n\u001b[32m      8\u001b[39m     inputs, labels = inputs.to(device), labels.to(device).float()\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m.squeeze()\n\u001b[32m     10\u001b[39m     predictions = (outputs >= \u001b[32m0.5\u001b[39m).float()\n\u001b[32m     11\u001b[39m     incorrect = (predictions != labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mPetCNN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     26\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool(F.relu(\u001b[38;5;28mself\u001b[39m.bn2(\u001b[38;5;28mself\u001b[39m.conv2(x))))\n\u001b[32m     27\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool(F.relu(\u001b[38;5;28mself\u001b[39m.bn3(\u001b[38;5;28mself\u001b[39m.conv3(x))))\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m x = \u001b[38;5;28mself\u001b[39m.pool(F.relu(\u001b[38;5;28mself\u001b[39m.bn4(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)))\n\u001b[32m     29\u001b[39m x = x.view(-\u001b[32m1\u001b[39m, \u001b[32m256\u001b[39m * \u001b[32m8\u001b[39m * \u001b[32m8\u001b[39m)\n\u001b[32m     30\u001b[39m x = F.relu(\u001b[38;5;28mself\u001b[39m.bn5(\u001b[38;5;28mself\u001b[39m.fc1(x)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1818\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1816\u001b[39m     hook_result = hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[32m   1817\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1818\u001b[39m     hook_result = \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1820\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1821\u001b[39m     result = hook_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchcam\\methods\\gradient.py:49\u001b[39m, in \u001b[36m_GradCAM._hook_g\u001b[39m\u001b[34m(self, module, input, output, idx)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Gradient hook\"\"\"\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._hooks_enabled:\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     \u001b[38;5;28mself\u001b[39m.hook_handles.append(\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_store_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:688\u001b[39m, in \u001b[36mTensor.register_hook\u001b[39m\u001b[34m(self, hook)\u001b[39m\n\u001b[32m    686\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.register_hook, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, hook)\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.requires_grad:\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    689\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcannot register a hook on a tensor that doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt require gradient\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    690\u001b[39m     )\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    692\u001b[39m     \u001b[38;5;28mself\u001b[39m._backward_hooks = OrderedDict()\n",
      "\u001b[31mRuntimeError\u001b[39m: cannot register a hook on a tensor that doesn't require gradient"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "misclassified_images = []\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        predictions = (outputs >= 0.5).float()\n",
    "        incorrect = (predictions != labels)\n",
    "\n",
    "        if incorrect.any():\n",
    "            misclassified_images.extend(inputs[incorrect].cpu())\n",
    "            true_labels.extend(labels[incorrect].cpu())\n",
    "            pred_labels.extend(predictions[incorrect].cpu())\n",
    "\n",
    "        if len(misclassified_images) >= 8:  # limit for visualization\n",
    "            break\n",
    "\n",
    "# Visualize misclassified images\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(min(8, len(misclassified_images))):\n",
    "    img = misclassified_images[i].numpy().transpose((1, 2, 0))\n",
    "    img = img * 0.5 + 0.5  # Denormalize\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"True: {'Cat' if true_labels[i]==0 else 'Dog'}\\nPred: {'Cat' if pred_labels[i]==0 else 'Dog'}\",\n",
    "              color='red')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PetCNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=16384, out_features=512, bias=True)\n",
       "  (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize your model instance\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = PetCNN().to(device)\n",
    "\n",
    "# Load the saved state_dict\n",
    "model.load_state_dict(torch.load('best_model.pt', map_location=device))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
